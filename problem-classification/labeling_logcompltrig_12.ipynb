{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Anna\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13855"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from io import StringIO\n",
    "from html.parser import HTMLParser\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    " \n",
    "nltk.download('stopwords')\n",
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "nltk_stopwords\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased',truncation_side='left',truncation=True)\n",
    "tokenizer.add_tokens(list(open('latex-vocabulary/latex_symbols.txt','r')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS device not found.\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=device)\n",
    "    print(x)\n",
    "else:\n",
    "    print(\"MPS device not found.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "\n",
    "def get_latex_from_alt(context):\n",
    "    strip_deliminators = lambda latex: latex.replace('$','').replace('\\\\[','').replace('\\\\]','')\n",
    "\n",
    "    context_soup = BeautifulSoup(context)\n",
    "    latex_images = context_soup.find_all('img')\n",
    "    for image in latex_images:\n",
    "        image.replace_with(strip_deliminators(image['alt']))\n",
    "    # return [strip_deliminators(image['alt']) for image in latex_images]\n",
    "    return str(context_soup)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    filtered_text = [w for w in text.split() if w.lower() not in nltk_stopwords]\n",
    "    return \" \".join(filtered_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening the JSON file where all the problems are stored:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html><head></head><body><p>Two of the three sides of a triangle are 20 and 15. Which of the following numbers is not a possible perimeter of the triangle?\\n</p><p>\\n</p></body></html>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems = json.load(open('amc_12_problems_with_sol.json'))\n",
    "problems[\"2015 AMC 12A #2\"][\"problem\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must filter for problems from before 2019 and get their problem, solutions, and choices.\n",
    "\n",
    "The following functions need to be applied to the text to simplify them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'problem' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m problem_text \u001b[38;5;241m=\u001b[39m strip_tags(get_latex_from_alt(\u001b[43mproblem\u001b[49m))\n\u001b[0;32m      2\u001b[0m solutions_text \u001b[38;5;241m=\u001b[39m strip_tags(get_latex_from_alt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([solution \u001b[38;5;28;01mfor\u001b[39;00m solution \u001b[38;5;129;01min\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(solutions_list) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m solution])))\n\u001b[0;32m      3\u001b[0m choices_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(json\u001b[38;5;241m.\u001b[39mloads(choices))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'problem' is not defined"
     ]
    }
   ],
   "source": [
    "problem_text = strip_tags(get_latex_from_alt(problem))\n",
    "solutions_text = strip_tags(get_latex_from_alt(\" \".join([solution for solution in json.loads(solutions_list) if 'http' not in solution])))\n",
    "choices_text = \" \".join(json.loads(choices))\n",
    "training_text = \" \".join([problem_text, solutions_text, choices_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part introduces how to apply the model to a certain string of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistilBERTClass(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(DistilBERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        return self.classifier(pooler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model must be downloaded: https://huggingface.co/yuppyd/top-level-with-solutions-distilbert-amc12-2019-2022/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\Anna\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\tokenization_utils_base.py:2674: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = DistilBERTClass(num_classes=5)\n",
    "model.to(device)\n",
    "model = torch.load('top-level-with-solutions-distilbert-amc12-2019-2022.pt',map_location=device)\n",
    "\n",
    "def outputs(input_string):\n",
    "    inputs = tokenizer.encode_plus(\n",
    "            input_string,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=256,\n",
    "            pad_to_max_length=True,\n",
    "            return_tensors=\"pt\").to(device)\n",
    "    fin_outputs = []\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    outputs = np.array(fin_outputs) >= 0.5\n",
    "    return [[1 if value else 0 for value in output] for output in outputs][0]\n",
    "\n",
    "testA = \"AMC 12A\"\n",
    "testB = \"AMC 12B\"\n",
    "output = \"\";\n",
    "for year in range(2015,2022):\n",
    "    for i in range(0,2):\n",
    "        for problem_num in range(1,26):\n",
    "            if i==0:\n",
    "                problem_ind = str(year)+\" \"+testA+\" #\"+str(problem_num)\n",
    "            elif i==1:\n",
    "                problem_ind = str(year)+\" \"+testB+\" #\"+str(problem_num)\n",
    "            try: \n",
    "                problem_text = strip_tags(get_latex_from_alt(problems[problem_ind][\"problem\"]))\n",
    "                solutions_text = strip_tags(get_latex_from_alt(\" \".join([solution for solution in problems[problem_ind][\"solutions\"] if 'http' not in solution])))\n",
    "                choices_text = \" \".join(problems[problem_ind][\"choices\"])\n",
    "                combined_text = remove_stopwords(\" \".join([problem_text, solutions_text, choices_text]))\n",
    "\n",
    "                assignment = outputs(combined_text)\n",
    "                if assignment==[0,0,0,0,0]:\n",
    "                    assignment[0] = 1;\n",
    "                output+=problem_ind+\": \"+str(assignment)+\"\\n\"\n",
    "\n",
    "                with open('outputs_file_12.txt', 'w') as f:\n",
    "                    f.write(output)\n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the outputs of every problem with their corresponding problem number / information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
